{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def corners_unwarp(cb_image, nx, ny, mtx, dist):\n",
    "    undistorted = cv2.undistort(cb_image, mtx, dist, None, mtx)\n",
    "    gray = cv2.cvtColor(undistorted, cv2.COLOR_RGB2GRAY)\n",
    "    image_w, image_h = gray.shape[1], gray.shape[0]\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    if not ret:\n",
    "        print('WARNING: Failed to detect corners for image {} with nx {} and ny {}'.format(image_fname, nx, ny))\n",
    "        return None, None\n",
    "\n",
    "    cv2.drawChessboardCorners(undistorted, (nx, ny), corners, ret)\n",
    "\n",
    "    src_tl = corners[0][0]\n",
    "    src_tr = corners[nx-1][0]\n",
    "    src_br = corners[-1][0]\n",
    "    src_bl = corners[-nx][0]\n",
    "\n",
    "    offset = 200\n",
    "    dst_tl = [offset, offset]\n",
    "    dst_tr = [image_w-offset, offset]\n",
    "    dst_br = [image_w-offset, image_h-offset]\n",
    "    dst_bl = [offset, image_h-offset]\n",
    "\n",
    "    src = np.float32([src_tl, src_tr, src_br, src_bl])\n",
    "    dst = np.float32([dst_tl, dst_tr, dst_br, dst_bl])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undistorted, M, gray.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, M\n",
    "\n",
    "\n",
    "class LaneLine():\n",
    "\n",
    "    def __init__(self):\n",
    "        # Calculate calibration parameters\n",
    "        cb_fnames = glob.glob('camera_cal/calibration*.jpg')\n",
    "        nx, ny = 9, 6\n",
    "        self.img_w, self.img_h = 1280, 720\n",
    "        self.mtx, self.dist = self.calibrate(cb_fnames, nx, ny, self.img_w, self.img_h, verbose=False)\n",
    "\n",
    "        # Calculate perspective transformation matrix\n",
    "        dst_offset = 400\n",
    "        src_bl, src_br, src_tl, src_tr = [190,720], [1090,720], [600,440], [680,440]\n",
    "        dst_bl, dst_br, dst_tl, dst_tr = [dst_offset,self.img_h], [self.img_w-dst_offset,self.img_h], [dst_offset,0], [self.img_w-dst_offset,0]\n",
    "        psp_src = np.float32([src_tl, src_tr, src_br, src_bl])\n",
    "        psp_dst = np.float32([dst_tl, dst_tr, dst_br, dst_bl])\n",
    "        self.M = cv2.getPerspectiveTransform(psp_src, psp_dst)\n",
    "\n",
    "        self.l_fit = None\n",
    "        self.r_fit = None\n",
    "        \n",
    "\n",
    "    def calibrate(self, fnames, nx, ny, img_w, img_h, verbose=False):\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "\n",
    "        objp = np.zeros((ny * nx, 3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "        if verbose:\n",
    "            print('Calibration started...')\n",
    "\n",
    "        for fname in fnames:\n",
    "            if verbose:\n",
    "                print('Finding chesshboard in {}'.format(fname))\n",
    "            img = mpimg.imread(fname)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "            if ret:\n",
    "                if verbose:\n",
    "                    print('Found chessboard in {}'.format(fname))\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img_w, img_h), None, None)\n",
    "        if not ret:\n",
    "            print('WARNING: Failed to calibrate camera')\n",
    "            return None, None\n",
    "\n",
    "        if verbose:\n",
    "            print('Calibration succeeded...')\n",
    "\n",
    "        return mtx, dist\n",
    "\n",
    "\n",
    "    def hls_select(self, img, chan, thresh=(0, 255)):\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        channel_s = hls[:,:,chan]\n",
    "        binary = np.zeros_like(channel_s)\n",
    "        binary[(channel_s > thresh[0]) & (channel_s <=thresh[1])] = 1\n",
    "        return binary\n",
    "\n",
    "\n",
    "    def abs_thresh(self, img, ksize=3, thresh=(0,255), orient='x'):\n",
    "        axis = 0 if orient == 'x' else 1\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        raw_sobel = cv2.Sobel(gray, cv2.CV_64F, 1-axis, axis, ksize=ksize)\n",
    "        abs_sobel = np.absolute(raw_sobel)\n",
    "        scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "        binary_output = np.zeros_like(scaled_sobel)\n",
    "        binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    def mag_thresh(self, img, ksize=3, thresh=(0,255)):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "        mag_sobel = np.sqrt(np.square(sobel_x) + np.square(sobel_y))\n",
    "        scaled_sobel = np.uint8(255 * mag_sobel / np.max(mag_sobel))\n",
    "        binary_output = np.zeros_like(scaled_sobel)\n",
    "        binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <=thresh[1])] = 1\n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    def dir_thresh(self, img, ksize=3, thresh=(0, np.pi/2)):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        abs_sobel_x = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize))\n",
    "        abs_sobel_y = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize))\n",
    "        dir_sobel = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "        binary_output = np.zeros_like(dir_sobel)\n",
    "        binary_output[(dir_sobel >= thresh[0]) & (dir_sobel <= thresh[1])] = 1\n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    def find_fits(self, img, n_windows=9, margin=100, minpix=50, draw=False):\n",
    "\n",
    "        # All non-zero pixel locations\n",
    "        nonzero = img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        # Indices found for pixels on lane lines\n",
    "        l_lane_idxs = []\n",
    "        r_lane_idxs = []\n",
    "\n",
    "        # Output to be drawn\n",
    "        out_img = None\n",
    "        if draw:\n",
    "            out_img = np.dstack((img, img, img))*255\n",
    "\n",
    "        # If we are passed in fits from last frame, then skip sliding window\n",
    "        reuse_fits = not (l_fit is None or r_fit is None)\n",
    "\n",
    "        if reuse_fits:\n",
    "            l_lane_idxs = ((nonzerox > (l_fit[0]*(nonzeroy**2) + l_fit[1]*nonzeroy + l_fit[2] - margin)) & (nonzerox < (l_fit[0]*(nonzeroy**2) + l_fit[1]*nonzeroy + l_fit[2] + margin)))\n",
    "            r_lane_idxs = ((nonzerox > (r_fit[0]*(nonzeroy**2) + r_fit[1]*nonzeroy + r_fit[2] - margin)) & (nonzerox < (r_fit[0]*(nonzeroy**2) + r_fit[1]*nonzeroy + r_fit[2] + margin)))\n",
    "        else:\n",
    "            # Histogram of bottom half of img\n",
    "            histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "            # Left and right x-coord at the base, and window height\n",
    "            midpoint = histogram.shape[0] // 2\n",
    "            xl_base = np.argmax(histogram[:midpoint])\n",
    "            xr_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "            window_h = img.shape[0] // n_windows\n",
    "            # Sliding window loop\n",
    "            xl_current = xl_base\n",
    "            xr_current = xr_base\n",
    "            for window in range(n_windows):\n",
    "                # Window boundaries\n",
    "                win_y_lo = img.shape[0] - window_h * (window + 1)\n",
    "                win_y_hi = img.shape[0] - window_h * window\n",
    "                # Left lane window\n",
    "                win_xl_lo = xl_current - margin\n",
    "                win_xl_hi = xl_current + margin\n",
    "                # Right lane window\n",
    "                win_xr_lo = xr_current - margin\n",
    "                win_xr_hi = xr_current + margin\n",
    "                # Find non-zero pixels within window\n",
    "                good_l_idxs = ((nonzeroy >= win_y_lo) & (nonzeroy < win_y_hi) & (nonzerox >= win_xl_lo) & (nonzerox < win_xl_hi)).nonzero()[0]\n",
    "                good_r_idxs = ((nonzeroy >= win_y_lo) & (nonzeroy < win_y_hi) & (nonzerox >= win_xr_lo) & (nonzerox < win_xr_hi)).nonzero()[0]\n",
    "                # Append to list of found indices\n",
    "                l_lane_idxs.append(good_l_idxs)\n",
    "                r_lane_idxs.append(good_r_idxs)\n",
    "                # If found more than minpix pixels, recenter next window on their mean position\n",
    "                if len(good_l_idxs) > minpix:\n",
    "                    xl_current = np.int(np.mean(nonzerox[good_l_idxs]))\n",
    "                if len(good_r_idxs) > minpix:\n",
    "                    xr_current = np.int(np.mean(nonzerox[good_r_idxs]))\n",
    "                # Draw window on output\n",
    "                if draw:\n",
    "                    cv2.rectangle(out_img,(win_xl_lo,win_y_lo),(win_xl_hi,win_y_hi),(0,0,255), 5)\n",
    "                    cv2.rectangle(out_img,(win_xr_lo,win_y_lo),(win_xr_hi,win_y_hi),(255,0,0), 5)\n",
    "            # Flatten\n",
    "            l_lane_idxs = np.concatenate(l_lane_idxs)\n",
    "            r_lane_idxs = np.concatenate(r_lane_idxs)\n",
    "\n",
    "        # Gather all pixel locations on lane lines\n",
    "        lx = nonzerox[l_lane_idxs]\n",
    "        ly = nonzeroy[l_lane_idxs]\n",
    "        rx = nonzerox[r_lane_idxs]\n",
    "        ry = nonzeroy[r_lane_idxs]\n",
    "\n",
    "        # Fit polynomial for each lane\n",
    "        new_l_fit = np.polyfit(ly, lx, 2)\n",
    "        new_r_fit = np.polyfit(ry, rx, 2)\n",
    "\n",
    "        self.l_fit = new_l_fit\n",
    "        self.r_fit = new_r_fit\n",
    "        \n",
    "        if draw:\n",
    "            # Draw pixels of detected lane lines\n",
    "            out_img[nonzeroy[l_lane_idxs], nonzerox[l_lane_idxs]] = [0,0,255]\n",
    "            out_img[nonzeroy[r_lane_idxs], nonzerox[r_lane_idxs]] = [255,0,0]\n",
    "            # Draw fitted lane lines\n",
    "            ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "            l_fit_x = new_l_fit[0] * ploty ** 2 + new_l_fit[1] * ploty + new_l_fit[2]\n",
    "            r_fit_x = new_r_fit[0] * ploty ** 2 + new_r_fit[1] * ploty + new_r_fit[2]\n",
    "            # window_img, used to add a weighted layer to out_img\n",
    "            window_img = np.zeros_like(out_img)\n",
    "            l_line_window1 = np.array([np.transpose(np.vstack([l_fit_x - margin, ploty]))])\n",
    "            l_line_window2 = np.array([np.flipud(np.transpose(np.vstack([l_fit_x + margin, ploty])))])\n",
    "            l_line_pts = np.hstack((l_line_window1, l_line_window2))\n",
    "            r_line_window1 = np.array([np.transpose(np.vstack([r_fit_x - margin, ploty]))])\n",
    "            r_line_window2 = np.array([np.flipud(np.transpose(np.vstack([r_fit_x + margin, ploty])))])\n",
    "            r_line_pts = np.hstack((r_line_window1, r_line_window2))\n",
    "            cv2.fillPoly(window_img, np.int_([l_line_pts]), (0,255, 0))\n",
    "            cv2.fillPoly(window_img, np.int_([r_line_pts]), (0,255, 0))\n",
    "            out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "            # Plot the above two lines\n",
    "            plt.imshow(out_img)\n",
    "            plt.plot(l_fit_x, ploty, color='yellow')\n",
    "            plt.plot(r_fit_x, ploty, color='yellow')\n",
    "            plt.xlim(0, self.img_w)\n",
    "            plt.ylim(self.img_h, 0)\n",
    "\n",
    "        return new_l_fit, new_r_fit, out_img\n",
    "\n",
    "\n",
    "    def undistort(self, img):\n",
    "        return cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "\n",
    "    def perspective(self, img):\n",
    "        return cv2.warpPerspective(img, self.M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    def thresh_img(self, img):\n",
    "        abs_x = abs_thresh(img, orient='x')\n",
    "        abs_y = abs_thresh(img, orient='y')\n",
    "        mag_t = mag_thresh(img, ksize=9, thresh=(30,100))\n",
    "        dir_t = dir_thresh(img)\n",
    "        return mag_thresh(img, ksize=9, thresh=(30,100))    \n",
    "    \n",
    "    def process_img(self, img, draw=False):\n",
    "        return self.find_fits(self.perspective(self.thresh_img(self.undistort(img))), draw=draw)\n",
    "\n",
    "    \n",
    "    def process_clip(self, video):\n",
    "        clip = VideoFileClip(video)\n",
    "        new_clip = clip.fl_image(self.process_img)\n",
    "        return new_clip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"project_video.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"project_video.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "thresh_img() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9146f120f037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLaneLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_video.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time out.write_videofile('test_output.mp4', audio=False)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-bbdb4fb13567>\u001b[0m in \u001b[0;36mprocess_clip\u001b[0;34m(self, video)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mnew_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-178>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \"\"\"\n\u001b[1;32m    652\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-135>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-bbdb4fb13567>\u001b[0m in \u001b[0;36mprocess_img\u001b[0;34m(self, img, draw)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_fits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: thresh_img() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "ll = LaneLine()\n",
    "out = ll.process_clip('project_video.mp4')\n",
    "%time out.write_videofile('test_output.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"test_output.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
